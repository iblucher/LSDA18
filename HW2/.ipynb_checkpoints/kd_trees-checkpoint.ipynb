{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to build a k-d tree for the training set X_train to speed up the nearest neighbour computations for the test set X_test. You are suppoesd to measure the runtimes needed for the training/fitting phase (i.e., for the construction of the tree) as well as for the testing/querying phase (i.e., for the tree traversal that yields the nearest neighbours for a given query point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import copy\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(n_train, n_test, dim):\n",
    "    \"\"\" This function generates a training set and\n",
    "    a test set containing random values. Make use of \n",
    "    this function to generate the datasets for your\n",
    "    experiments.\n",
    "    \"\"\"\n",
    "    \n",
    "    numpy.random.seed(0)\n",
    "    \n",
    "    if n_train is not None:\n",
    "        X_train = numpy.random.random((n_train, dim))\n",
    "    else:\n",
    "        X_train = None\n",
    "            \n",
    "    if n_test is not None:\n",
    "        X_test = numpy.random.random((n_test, dim))\n",
    "    else:\n",
    "        X_test = None\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neighbours():\n",
    "    \"\"\" Class that can be used to keep track of the \n",
    "    k nearest neighbours computed. It also conducts\n",
    "    the \"brute-force\" phase that takes place in the\n",
    "    leaves of a k-d tree (see function 'add').\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k):\n",
    "        \n",
    "        self.k = k \n",
    "        self._neighbors = [(None, None, float(\"inf\")) for i in range(self.k)]\n",
    "\n",
    "    def get_dists_indices(self):\n",
    "        \n",
    "        indices = [neigh[1] for neigh in self._neighbors]\n",
    "        dists = [neigh[2] for neigh in self._neighbors]\n",
    "        \n",
    "        return numpy.array(dists), numpy.array(indices)\n",
    "    \n",
    "    def add(self, points, indices, query):\n",
    "\n",
    "        for i in range(len(points)):\n",
    "            \n",
    "            p = points[i]\n",
    "            idx = indices[i]\n",
    "            dist = self._distance(p, query)\n",
    "            \n",
    "            self._neighbors.append([p,idx,dist])\n",
    "            self._neighbors = sorted(self._neighbors, key=lambda n: n[2])\n",
    "            self._neighbors = self._neighbors[:self.k]\n",
    "\n",
    "    def get_max_dist(self):\n",
    "        \n",
    "        return self._neighbors[-1][2]\n",
    "        \n",
    "    def _distance(self, x, y):\n",
    "        \n",
    "        dist = 0.0\n",
    "        for j in range(len(x)):\n",
    "            dist += (x[j] - y[j])**2\n",
    "            \n",
    "        return math.sqrt(dist)\n",
    "    \n",
    "class Node():\n",
    "    \"\"\" Class that represents a single node of\n",
    "    a k-d tree. If both 'left' and 'right' are \n",
    "    None, then the node is a leaf. The local \n",
    "    variables 'points' and 'indices' are used\n",
    "    to store the points/indices assigned to a \n",
    "    leaf.\n",
    "    \n",
    "    Otherwise, it is an internal node that \n",
    "    stores the median (splitting hyperplane)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 left, \n",
    "                 right, \n",
    "                 median=None, \n",
    "                 points=None, \n",
    "                 indices=None):\n",
    "\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.median = median\n",
    "        self.points = points\n",
    "        self.indices = indices\n",
    "        \n",
    "class KDTree():\n",
    "    \n",
    "    def __init__(self, leaf_size=30):\n",
    "        \"\"\" Instantiates a k-d tree.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        leaf_size : int, default 30\n",
    "            The leaf size, i.e., the maximal \n",
    "            number of points stored in a leaf \n",
    "            of the k-d tree.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.leaf_size = leaf_size\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n, d)\n",
    "            A Numpy array containing n data \n",
    "            points each having d features                \n",
    "        \"\"\"\n",
    "        \n",
    "        # remember dimension for which the tree was built\n",
    "        self._dim = len(X[0])\n",
    "        \n",
    "        # generate a list of the \"original\" indices that\n",
    "        # are processed in a similar way as the points; \n",
    "        # this is needed in order to obtain the indices\n",
    "        # of the neighbours compuated for a query.\n",
    "        original_indices = numpy.array(range(len(X)))\n",
    "        \n",
    "        # build tree recursively\n",
    "        self._root = self._build_tree(copy.deepcopy(X),\n",
    "                                      original_indices, \n",
    "                                      depth=0)\n",
    "        \n",
    "    def query(self, X, k=1):\n",
    "        \"\"\" Computes the k nearest neighbors for each \n",
    "        point in X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n, d)\n",
    "            A Numpy array containing n data \n",
    "            points each having d features\n",
    "        k : int, default 1\n",
    "            The number of nearest neighbours to \n",
    "            be computed\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        dists, indices : arrays of shape (n, k)\n",
    "            Two arrays containing, for each query point,\n",
    "            the distances and the associated indices of\n",
    "            its k nearest neighbors w.r.t. the points\n",
    "            used for building the tree.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self._root is None:  \n",
    "            raise Exception(\"Tree not fitted yet!\")\n",
    "            \n",
    "        if len(X[0]) != self._dim:\n",
    "            raise Exception(\"Tree was fitted for points of dimension: {}\".format(self._dim))\n",
    "        \n",
    "        # initialize two empty arrays that will be used to \n",
    "        # store the distances and the associated indices\n",
    "        dists = numpy.empty((len(X), k), dtype=numpy.float64)\n",
    "        indices = numpy.empty((len(X), k), dtype=numpy.int32)\n",
    "        \n",
    "        # iterate over all query points\n",
    "        for i in range(len(X)):\n",
    "\n",
    "            # initialize the neighbours object, which\n",
    "            # will keep track of the nearest neighbours\n",
    "            neighbours = Neighbours(k)\n",
    "            \n",
    "            # start recursive search\n",
    "            self._recursive_search(self._root, \n",
    "                                   X[i], \n",
    "                                   k, \n",
    "                                   depth=0, \n",
    "                                   neighbours=neighbours)\n",
    "            \n",
    "            # get the final distances and indices for \n",
    "            # the current query and store them at \n",
    "            # position i in the arrays dists and indices \n",
    "            dists_query, indices_query = neighbours.get_dists_indices()\n",
    "            dists[i,:] = dists_query\n",
    "            indices[i,:] = indices_query\n",
    "                \n",
    "        return dists, indices\n",
    "    \n",
    "    def _build_tree(self, pts, indices, depth):\n",
    "        \"\"\" Builds a k-d tree for the points given in pts. Since\n",
    "        we are also interested in the indidces afterwards, we also\n",
    "        keep track of the (original) indices.\n",
    "        \n",
    "        This code is similar to the pseudocode given on \n",
    "        slides 27-29 of L3_LSDA.pdf\n",
    "        \"\"\"\n",
    "        \n",
    "        # if only self.leaf_size points are left, stop\n",
    "        # the recursion and generate a leaf node\n",
    "        if len(pts) <= self.leaf_size: \n",
    "            \n",
    "            return Node(left=None, \n",
    "                        right=None, \n",
    "                        points=pts, \n",
    "                        indices=indices)\n",
    "        \n",
    "        # select axis\n",
    "        axis = depth % self._dim\n",
    "        \n",
    "        # sort the points w.r.t. dimension 'axis';\n",
    "        # also sort the indices accordingly\n",
    "        partition = pts[:,axis].argsort()\n",
    "        pts = pts[partition]\n",
    "        indices = indices[partition]\n",
    "        \n",
    "        # compute splitting index and median value\n",
    "        split_idx = math.floor(len(pts) / 2)\n",
    "        if len(pts) % 2 == 1:\n",
    "            median = pts[split_idx, axis]\n",
    "        else:\n",
    "            median = 0.5 * (pts[split_idx, axis] + pts[split_idx+1, axis])\n",
    "        \n",
    "        # build trees for children recursively ...\n",
    "        lefttree = self._build_tree(pts[:split_idx,:], indices[:split_idx], depth+1)\n",
    "        righttree = self._build_tree(pts[split_idx:,:], indices[split_idx:], depth+1)\n",
    "        \n",
    "        # return node storing all the relevant information\n",
    "        return Node(left=lefttree, right=righttree, median=median)\n",
    "\n",
    "    def _recursive_search(self, node, query, k, depth, neighbours):\n",
    "        \n",
    "        if (node.left == None and node.right==None):\n",
    "            neighbours.add(node.points, node.indices, query)\n",
    "            return\n",
    "    \n",
    "        # axis to be checked (same order as during construction)\n",
    "        axis = depth % self._dim\n",
    "\n",
    "        # select next subtree candidate\n",
    "        if query[axis] < node.median:\n",
    "            first = node.left\n",
    "            second = node.right\n",
    "        else:\n",
    "            first = node.right\n",
    "            second = node.left\n",
    "\n",
    "        # check first subtree\n",
    "        self._recursive_search(first, query, k, depth+1, neighbours)\n",
    "\n",
    "        # while going up again (to the root): check if we \n",
    "        # still have to search in the second subtree! \n",
    "        if abs(node.median - query[axis]) < neighbours.get_max_dist():\n",
    "            self._recursive_search(second, query, k, depth+1, neighbours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a small sanity check by comparing the distances and the indices computed with the ones obtained via the Scikit-Learn implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree as KDTreeSK\n",
    "\n",
    "# generate toy datasets\n",
    "X_train, X_test = get_datasets(1000, 100, 10)\n",
    "\n",
    "# our implementation (see above)\n",
    "tree = KDTree(leaf_size=20)\n",
    "tree.fit(X_train)\n",
    "dists, indices = tree.query(X_test, k=3)  \n",
    "\n",
    "# reference implementation (scikit-learn)\n",
    "tree = KDTreeSK(X_train, leaf_size=20)  \n",
    "sk_dists, sk_indices = tree.query(X_test, k=3)\n",
    "\n",
    "# check if computed arrays are the same\n",
    "dists_ok = numpy.allclose(dists, sk_dists)\n",
    "indices_ok = numpy.allclose(indices, sk_indices)\n",
    "print(\"Distances correct: {}\".format(dists_ok))\n",
    "print(\"Indices correct: {}\".format(dists_ok))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practical Runtimes (a):** Analyze the runtime behaviour for the training/fitting phase given different dimensions of the feature space and given an increasing amount of training points. Your plot (n_train vs. runtime) should generate 5 graphs, one for each dim=5,10,15,20,25. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_trains = [i*10000 for i in range(1,11)]\n",
    "dims = [5,10,15,20,25]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for dim in dims:\n",
    "\n",
    "    print(\"Processing patterns of dimension {} ...\".format(dim))\n",
    "\n",
    "    # YOUR RUNTIME MEASUREMENTS AND GRAPHS HERE \n",
    "    #\n",
    "    # for each n_train in n_trains, do\n",
    "    # - generate training set X_train of size n_train and dimensionality dim\n",
    "    # - create a k-d tree object tree\n",
    "    # - measure time needed for tree.fit(X_train)\n",
    "    # - create runtime graph; all graphs should be in the same plot\n",
    "    \n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practical Runtimes (b):** Analyze the runtime behaviour for the testing/querying phase given different dimensions of the feature space and given an increasing amount of test points. Your plot (n_test vs. runtime) should generate 5 graphs, one for each dim=5,10,15,20,25. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 10000\n",
    "n_tests = [i*10 for i in range(1,11)]\n",
    "dims = [5,10,15,20,25]\n",
    "\n",
    "# YOUR RUNTIME MEASUREMENTS AND GRAPHS HERE \n",
    "# (note: the runtime experiment might take some minutes)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Runtime Profiling:** Make use of the cProfile module to profile the query phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "\n",
    "X_train, X_test = get_datasets(10000, 100, 50)\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
