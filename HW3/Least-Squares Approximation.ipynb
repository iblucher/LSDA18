{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy\n",
    "numpy.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(n=250):\n",
    "    \"\"\" Creates a simple 1D dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    numpy.random.seed(0)\n",
    "    \n",
    "    X = numpy.linspace(0, 3*numpy.pi, n)\n",
    "    y = 0.5*numpy.sin(X) + numpy.random.normal(0, 0.1, n)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeastSquaresRegression():\n",
    "    \n",
    "    def __init__(self, lam=1.0, kernel=\"rbf\", gamma=1.0, r=None, random_state=0):\n",
    "        \"\"\" Instantiates the regression model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        lam : float, default 1.0\n",
    "            The regularization parameter lambda\n",
    "        kernel : string, default 'rbf'\n",
    "            The kernel to be used\n",
    "        gamma : float, default 1.0\n",
    "            The kernel width gamma for the RBF kernel\n",
    "        r : int or None, default None\n",
    "            If None, then use all the training instances\n",
    "            to represent the model. Otherwise, only \n",
    "            r random training instances are used (1 <= r <= n).\n",
    "        random_state : int, default 0\n",
    "            The random state (seed) to be used.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.lam = lam\n",
    "        self.kernel = kernel\n",
    "        self.gamma = gamma\n",
    "        self.r = r\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\" Returns the parameters of the model\n",
    "        \"\"\"\n",
    "        \n",
    "        return {\"lam\": self.lam, \n",
    "                \"kernel\": self.kernel, \n",
    "                \"gamma\": self.gamma, \n",
    "                \"r\": self.r,\n",
    "                \"random_state\": self.random_state}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        \"\"\" Sets the parameters of the model\n",
    "        \"\"\"        \n",
    "        \n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fits the regression model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Array of shape [n_samples, n_features]\n",
    "        y : Array of shape [n_samples, 1]\n",
    "        \"\"\"   \n",
    "        \n",
    "        numpy.random.seed(self.random_state)\n",
    "        \n",
    "        # make sure that we have numpy arrays; also\n",
    "        # reshape the array X to ensure that we have\n",
    "        # a multidimensional numpy array (ndarray);\n",
    "        # for y, we want to have a column vector\n",
    "        X = numpy.array(X).reshape((X.shape[0], -1))\n",
    "        y = numpy.array(y).reshape((len(y), 1))\n",
    "\n",
    "        self._Xtrain = X\n",
    "        self._ytrain = y\n",
    "        \n",
    "        if self.r is None:\n",
    "        \n",
    "            km = self._compute_kernel_matrix(self._Xtrain, self._Xtrain)\n",
    "            shifted_km = km + len(self._ytrain) * self.lam * numpy.identity(len(self._Xtrain))\n",
    "\n",
    "            # Ex 1.1: ADAPT THE CODE HERE\n",
    "            #self._c = numpy.dot(numpy.linalg.inv(shifted_km), self._ytrain)  \n",
    "            self._c = numpy.linalg.solve(shifted_km, self._ytrain)\n",
    "            \n",
    "        else:\n",
    "\n",
    "            assert self.r >= 1\n",
    "            assert self.r <= X.shape[0]\n",
    "            \n",
    "            rsub = numpy.random.choice(X.shape[0], self.r, replace=False)\n",
    "            self._Xtrain_sub = self._Xtrain[rsub]\n",
    "            self._ytrain_sub = self._ytrain[rsub]\n",
    "            \n",
    "            # Ex 1.3: YOUR CODE HERE\n",
    "            # (make sure that you also use numpy.linalg.solve here)\n",
    "            \n",
    "            km = self._compute_kernel_matrix(self._Xtrain_sub, self._Xtrain_sub)\n",
    "            shifted_km = km + len(self._ytrain_sub) * self.lam * numpy.identity(len(self._Xtrain_sub))\n",
    "            self._c = numpy.linalg.solve(shifted_km, self._ytrain_sub)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def fit_shortcut(self, X, y, lam=1.0):\n",
    "        \"\"\"\n",
    "        Fits the regression model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Array of shape [n_samples, n_features]\n",
    "        y : Array of shape [n_samples, 1]\n",
    "        \"\"\"   \n",
    "        \n",
    "        numpy.random.seed(self.random_state)\n",
    "        \n",
    "        # make sure that we have numpy arrays; also\n",
    "        # reshape the array X to ensure that we have\n",
    "        # a multidimensional numpy array (ndarray);\n",
    "        # for y, we want to have a column vector\n",
    "        X = numpy.array(X).reshape((X.shape[0], -1))\n",
    "        y = numpy.array(y).reshape((len(y), 1))\n",
    "\n",
    "        self._Xtrain = X\n",
    "        self._ytrain = y\n",
    "        self.lam = lam\n",
    "        \n",
    "        if self.r is None:\n",
    "\n",
    "            # Ex 1.4: YOUR CODE HERE\n",
    "            km = self._compute_kernel_matrix(self._Xtrain, self._Xtrain)\n",
    "            evals, evecs = numpy.linalg.eigh(km)\n",
    "            d = numpy.diag(evals)\n",
    "            B1 = numpy.dot(numpy.transpose(evecs), self._ytrain)\n",
    "            B2 = numpy.linalg.inv(d + len(self._ytrain) * self.lam * numpy.identity(len(self._Xtrain)))\n",
    "            B3 = numpy.dot(B2, B1)\n",
    "            self._c = numpy.dot(evecs, B3)\n",
    "                        \n",
    "        else:\n",
    "\n",
    "            assert self.r >= 1\n",
    "            assert self.r <= X.shape[0]\n",
    "            \n",
    "            # Not needed to be implemented for this homework!\n",
    "            raise Exception(\"Not part of this homework\")\n",
    "\n",
    "        return self    \n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Computes predictions for a new set of points.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Array of shape [n_samples, n_features]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        predictions : Array of shape [n_samples, 1]\n",
    "        \"\"\"           \n",
    "        \n",
    "        # make sure that we have numpy arrays; also\n",
    "        # reshape the array X to ensure that we have\n",
    "        # a multidimensional numpy array (ndarray)\n",
    "        X = numpy.array(X).reshape((X.shape[0], -1))\n",
    "\n",
    "        if self.r is None:\n",
    "            \n",
    "            km = self._compute_kernel_matrix(X, self._Xtrain)\n",
    "            preds = numpy.dot(km, self._c)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # Ex 1.3: YOUR CODE HERE\n",
    "            km = self._compute_kernel_matrix(X, self._Xtrain_sub)\n",
    "            preds = numpy.dot(km, self._c)\n",
    "    \n",
    "        return preds\n",
    "            \n",
    "    def _compute_kernel_matrix(self, X1, X2):\n",
    "        \"\"\" Computes the kernel matrix\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.kernel == \"rbf\":\n",
    "            \n",
    "            km = numpy.empty((X1.shape[0], X2.shape[0]), dtype=numpy.float64)\n",
    "            \n",
    "            for i in range(X1.shape[0]):\n",
    "                for j in range(X2.shape[0]):\n",
    "                    diff = X1[i] - X2[j]\n",
    "                    tmp = numpy.dot(diff, diff)\n",
    "                    km[i,j] = numpy.exp(- self.gamma * tmp)\n",
    "\n",
    "            return km\n",
    "        \n",
    "        elif self.kernel == \"fast_rbf\":\n",
    "            \n",
    "            # Ex 1.2: YOUR CODE HERE\n",
    "            km = numpy.empty((X1.shape[0], X2.shape[0]), dtype=numpy.float64)\n",
    "            prod = numpy.dot(X1, numpy.transpose(X2))\n",
    "            p = -self.gamma * prod\n",
    "            e = numpy.full((prod.shape), numpy.exp(1))\n",
    "            km = numpy.power(e, p)\n",
    "            km = numpy.array(km)\n",
    "            \n",
    "            return km\n",
    "            \n",
    "                    \n",
    "        else:\n",
    "            \n",
    "            raise Exception(\"Unknown kernel: {}\".format(self.kernel))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes: Let's generate some toy data to illustrate the effect of the different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = get_dataset()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "lams = [10, 0.01, 0.0001]\n",
    "gammas = [0.1, 2, 1000]\n",
    "\n",
    "f, axes = plt.subplots(1, 3, sharey=True, figsize=(15,5))\n",
    "\n",
    "for (lam, gamma, i) in zip(lams, gammas, range(len(lams))):\n",
    "\n",
    "    model = LeastSquaresRegression(kernel=\"rbf\", lam=lam, gamma=gamma)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    # plot test points and predictions\n",
    "    axes[i].scatter(X_test, y_test, s=100, c=\"b\", edgecolor=\"k\", linewidths=1, label=\"True\")\n",
    "    axes[i].scatter(X_test, preds, s=100, c=\"r\", edgecolor=\"k\", linewidths=1, label=\"Predictions\")\n",
    "\n",
    "    # plot model\n",
    "    x = numpy.linspace(X.min(), X.max(), 500)\n",
    "    axes[i].plot(x, model.predict(x), \"-k\", alpha=0.8, linewidth=3.0, label=\"Model\")\n",
    "\n",
    "    axes[i].set_xlabel(\"X\")\n",
    "    axes[i].set_ylabel(\"y\")\n",
    "    axes[i].legend(loc=0)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 1.1: Avoid the computation of the inverse of the matrix;\n",
    "# instead, make use of numpy.linalg.solve. Afterwards, measure \n",
    "# the runtimes needed by the fit function for datasets of \n",
    "# increasing size n (see below)\n",
    "\n",
    "import time\n",
    "\n",
    "n_range = [100*i for i in range(1,11)]\n",
    "\n",
    "lam = 0.01\n",
    "gamma = 2.0\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "results_exact = []\n",
    "\n",
    "for n in n_range:\n",
    "    \n",
    "    print(\"Processing dataset of size {} ...\".format(n))\n",
    "\n",
    "    X_train, y_train = get_dataset(n=n)\n",
    "\n",
    "    start = time.time()\n",
    "    model = LeastSquaresRegression(kernel=\"rbf\", lam=lam, gamma=gamma)\n",
    "    model.fit(X_train, y_train)      \n",
    "    end = time.time()\n",
    "    \n",
    "    results_exact.append(end-start)        \n",
    "        \n",
    "ax.plot(range(1,11), results_exact, label=\"runtime (exact)\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 1.2: Accelerate the computation of the kernel matrix \n",
    "# by make use of more efficient Numpy array operations. That\n",
    "# is, try to avoid the two neested Python loops and the \n",
    "# individual kernel value computations. Extend the code by\n",
    "# providing a 'new' kernel 'fast_rbf', see above. Conduct a \n",
    "# similar runtime experiment as before (new plot). Which \n",
    "# speed-up do you get for n=1000 training instances?\n",
    "\n",
    "import time\n",
    "\n",
    "n_range = [100*i for i in range(1,11)]\n",
    "\n",
    "lam = 0.01\n",
    "gamma = 1.0\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "results_exact = []\n",
    "results_exact_fast = []\n",
    "\n",
    "for n in n_range:\n",
    "    \n",
    "    print(\"Processing dataset of size {} ...\".format(n))\n",
    "\n",
    "    X_train, y_train = get_dataset(n=n)\n",
    "\n",
    "    start = time.time()\n",
    "    model = LeastSquaresRegression(kernel=\"rbf\", lam=lam, gamma=gamma)\n",
    "    model.fit(X_train, y_train)      \n",
    "    end = time.time()\n",
    "    results_exact.append(end-start)        \n",
    "    \n",
    "    start = time.time()\n",
    "    model = LeastSquaresRegression(kernel=\"fast_rbf\", lam=lam, gamma=gamma)\n",
    "    model.fit(X_train, y_train)      \n",
    "    end = time.time()\n",
    "    results_exact_fast.append(end-start)            \n",
    "        \n",
    "ax.plot(range(1,11), results_exact, label=\"runtime (exact)\")\n",
    "ax.plot(range(1,11), results_exact_fast, label=\"runtime (exact, fast)\")\n",
    "ax.legend()\n",
    "plt.show()\n",
    "print(\"Speed-Up: {}\".format(results_exact[-1] / results_exact_fast[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 1.3: \n",
    "# - Extend the class LeastSquaresRegression such \n",
    "#   that it implements the approximation scheme discussed\n",
    "#   during the lecture that resorts models being based on\n",
    "#   only r training instances.\n",
    "# - conduct a similar runtime experiment as above and\n",
    "#   compare the runtimes of the exact approach with the \n",
    "#   ones of the approximation scheme (see below)\n",
    "\n",
    "# NOTE: Use n_range = [100*i for i in range(1,11)] in case \n",
    "# you have to make use of the slow kernel='rbf'\n",
    "\n",
    "n_range = [500*i for i in range(1,11)]\n",
    "\n",
    "lam = 0.01\n",
    "gamma = 1.0\n",
    "r = 50\n",
    "\n",
    "import time\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "results_exact_fast = []\n",
    "results_approx = []\n",
    "\n",
    "for n in n_range:\n",
    "    \n",
    "    print(\"Processing dataset of size {} ...\".format(n))\n",
    "\n",
    "    X_train, y_train = get_dataset(n=n)\n",
    "    \n",
    "    start = time.time()\n",
    "    model = LeastSquaresRegression(kernel=\"fast_rbf\", lam=lam, gamma=gamma)\n",
    "    model.fit(X_train, y_train)      \n",
    "    end = time.time()\n",
    "    results_exact_fast.append(end-start)            \n",
    "    \n",
    "    start = time.time()\n",
    "    model = LeastSquaresRegression(kernel=\"fast_rbf\", lam=lam, gamma=gamma, r=50)\n",
    "    model.fit(X_train, y_train)      \n",
    "    end = time.time()\n",
    "    results_approx.append(end-start)\n",
    "        \n",
    "ax.plot(range(1,11), results_exact_fast, label=\"runtime (exact, fast)\")\n",
    "ax.plot(range(1,11), results_approx, label=\"runtime (approx, fast)\")\n",
    "ax.legend()\n",
    "plt.show()\n",
    "print(\"Speed-Up: {}\".format(results_exact_fast[-1] / results_approx[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.2249376773834229\n",
      "Elapsed time: 1.199836254119873\n",
      "Elapsed time: 1.014040231704712\n",
      "Elapsed time: 1.2092278003692627\n",
      "Elapsed time: 1.4433608055114746\n",
      "Elapsed time: 1.7885363101959229\n",
      "Elapsed time: 1.4236512184143066\n",
      "Elapsed time: 1.4199721813201904\n",
      "Elapsed time: 1.4394309520721436\n",
      "Elapsed time: 1.463561773300171\n",
      "Elapsed time: 1.449247121810913\n",
      "Elapsed time: 1.403289794921875\n",
      "Elapsed time: 1.4171481132507324\n",
      "Elapsed time: 1.3885722160339355\n",
      "Elapsed time: 1.4725542068481445\n",
      "Elapsed time: 1.6538848876953125\n",
      "Elapsed time: 1.56685209274292\n",
      "Elapsed time: 1.6682331562042236\n",
      "Elapsed time: 1.6275303363800049\n",
      "Elapsed time: 1.4220483303070068\n",
      "Elapsed time: 1.4102106094360352\n",
      "Elapsed time: 1.4012248516082764\n",
      "Elapsed time: 1.4622769355773926\n",
      "Elapsed time: 1.419452428817749\n",
      "Elapsed time: 1.4004435539245605\n",
      "Elapsed time: 1.4054358005523682\n",
      "Elapsed time: 1.629991054534912\n",
      "Elapsed time: 2.3323047161102295\n",
      "Elapsed time: 3.699841260910034\n",
      "Elapsed time: 2.8896069526672363\n",
      "Elapsed time: 2.4164626598358154\n",
      "Elapsed time: 1.986121654510498\n",
      "Elapsed time: 2.23754620552063\n",
      "Elapsed time: 2.253690719604492\n",
      "Elapsed time: 1.594606637954712\n",
      "Elapsed time: 1.732051134109497\n",
      "Elapsed time: 2.3847479820251465\n",
      "Elapsed time: 1.791558027267456\n",
      "Elapsed time: 1.4319067001342773\n",
      "Elapsed time: 1.368274450302124\n",
      "Elapsed time: 1.3985834121704102\n",
      "Elapsed time: 1.411957025527954\n",
      "Elapsed time: 1.4132351875305176\n",
      "Elapsed time: 1.4122600555419922\n",
      "Elapsed time: 1.388108491897583\n",
      "Elapsed time: 1.4233624935150146\n",
      "Elapsed time: 1.393354892730713\n",
      "Elapsed time: 1.480022668838501\n",
      "Elapsed time: 1.8418359756469727\n",
      "Elapsed time: 1.6129796504974365\n",
      "Elapsed time: 1.6374881267547607\n",
      "Elapsed time: 1.4274201393127441\n",
      "Elapsed time: 1.5220205783843994\n",
      "Elapsed time: 1.4283947944641113\n",
      "Elapsed time: 1.4172923564910889\n",
      "Elapsed time: 1.4022252559661865\n",
      "Elapsed time: 1.4043691158294678\n",
      "Elapsed time: 1.4517428874969482\n",
      "Elapsed time: 1.4126155376434326\n",
      "Elapsed time: 1.423027515411377\n",
      "Elapsed time: 1.4134793281555176\n",
      "Elapsed time: 1.4276361465454102\n",
      "Elapsed time: 1.4142518043518066\n",
      "Elapsed time: 1.402099609375\n",
      "Elapsed time: 1.4007453918457031\n",
      "Elapsed time: 1.502992868423462\n",
      "Elapsed time: 1.4490416049957275\n",
      "Elapsed time: 1.4168827533721924\n",
      "Elapsed time: 1.3944263458251953\n",
      "Elapsed time: 1.4280340671539307\n",
      "Elapsed time: 1.4234693050384521\n",
      "Elapsed time: 1.4021596908569336\n",
      "Elapsed time: 1.4140121936798096\n",
      "Elapsed time: 1.4352858066558838\n",
      "Elapsed time: 1.5335686206817627\n",
      "Elapsed time: 1.709277629852295\n",
      "Elapsed time: 2.5846235752105713\n",
      "Elapsed time: 1.625326156616211\n",
      "Elapsed time: 1.4094350337982178\n",
      "Elapsed time: 1.4162890911102295\n",
      "Elapsed time: 2.1287436485290527\n",
      "Elapsed time: 2.688896656036377\n",
      "Elapsed time: 1.430588722229004\n",
      "Elapsed time: 1.4061279296875\n",
      "Elapsed time: 1.44816255569458\n",
      "Elapsed time: 1.4088633060455322\n",
      "Elapsed time: 1.3938992023468018\n",
      "Elapsed time: 1.3995859622955322\n",
      "Elapsed time: 1.4146654605865479\n",
      "Elapsed time: 1.4018287658691406\n",
      "Elapsed time: 1.4001431465148926\n",
      "Elapsed time: 1.3977751731872559\n",
      "Elapsed time: 1.4112637042999268\n",
      "Elapsed time: 1.4259109497070312\n",
      "Elapsed time: 1.4052982330322266\n",
      "Elapsed time: 1.4006152153015137\n",
      "Elapsed time: 1.4817132949829102\n",
      "Elapsed time: 1.39863920211792\n",
      "Elapsed time: 1.4113974571228027\n",
      "Elapsed time: 1.4148802757263184\n",
      "Elapsed time: 0.2393505573272705\n",
      "Elapsed time: 0.3405461311340332\n",
      "Elapsed time: 0.22229361534118652\n",
      "Elapsed time: 0.3398172855377197\n",
      "Elapsed time: 0.21489524841308594\n",
      "Elapsed time: 0.3531203269958496\n",
      "Elapsed time: 0.5187437534332275\n",
      "Elapsed time: 0.33058953285217285\n",
      "Elapsed time: 0.2168288230895996\n",
      "Elapsed time: 0.31296610832214355\n",
      "Elapsed time: 0.21886658668518066\n",
      "Elapsed time: 0.3193371295928955\n",
      "Elapsed time: 0.28656649589538574\n",
      "Elapsed time: 0.34406232833862305\n",
      "Elapsed time: 0.2006833553314209\n",
      "Elapsed time: 0.3562443256378174\n",
      "Elapsed time: 0.3419923782348633\n",
      "Elapsed time: 0.20080065727233887\n",
      "Elapsed time: 0.32699155807495117\n",
      "Elapsed time: 0.19893765449523926\n",
      "Elapsed time: 0.31842851638793945\n",
      "Elapsed time: 0.19923043251037598\n",
      "Elapsed time: 0.2671818733215332\n",
      "Elapsed time: 0.19971203804016113\n",
      "Elapsed time: 0.3218076229095459\n",
      "Elapsed time: 0.20045876502990723\n",
      "Elapsed time: 0.32205772399902344\n",
      "Elapsed time: 0.2030038833618164\n",
      "Elapsed time: 0.313262939453125\n",
      "Elapsed time: 0.19423866271972656\n",
      "Elapsed time: 0.25907421112060547\n",
      "Elapsed time: 0.20003104209899902\n",
      "Elapsed time: 0.3010237216949463\n",
      "Elapsed time: 0.1917104721069336\n",
      "Elapsed time: 0.2709164619445801\n",
      "Elapsed time: 0.213517427444458\n",
      "Elapsed time: 0.311267614364624\n",
      "Elapsed time: 0.2203807830810547\n",
      "Elapsed time: 0.3195955753326416\n",
      "Elapsed time: 0.20219182968139648\n",
      "Elapsed time: 0.3074836730957031\n",
      "Elapsed time: 0.22800421714782715\n",
      "Elapsed time: 0.31560564041137695\n",
      "Elapsed time: 0.21172642707824707\n",
      "Elapsed time: 0.3100461959838867\n",
      "Elapsed time: 0.2248697280883789\n",
      "Elapsed time: 0.307783842086792\n",
      "Elapsed time: 0.20537781715393066\n",
      "Elapsed time: 0.31628918647766113\n",
      "Elapsed time: 0.23614144325256348\n",
      "Elapsed time: 0.26805663108825684\n",
      "Elapsed time: 0.26535558700561523\n",
      "Elapsed time: 0.2650339603424072\n",
      "Elapsed time: 0.24771428108215332\n",
      "Elapsed time: 0.2486708164215088\n",
      "Elapsed time: 0.23781895637512207\n",
      "Elapsed time: 0.25958871841430664\n",
      "Elapsed time: 0.26940488815307617\n",
      "Elapsed time: 0.2650172710418701\n",
      "Elapsed time: 0.24587154388427734\n",
      "Elapsed time: 0.2687649726867676\n",
      "Elapsed time: 0.22599244117736816\n",
      "Elapsed time: 0.3081207275390625\n",
      "Elapsed time: 0.23717904090881348\n",
      "Elapsed time: 0.28004026412963867\n",
      "Elapsed time: 0.2323753833770752\n",
      "Elapsed time: 0.31046319007873535\n",
      "Elapsed time: 0.2032928466796875\n",
      "Elapsed time: 0.3258383274078369\n",
      "Elapsed time: 0.19993257522583008\n",
      "Elapsed time: 0.3012077808380127\n",
      "Elapsed time: 0.19179439544677734\n",
      "Elapsed time: 0.2780416011810303\n",
      "Elapsed time: 0.20056509971618652\n",
      "Elapsed time: 0.29395294189453125\n",
      "Elapsed time: 0.2052924633026123\n",
      "Elapsed time: 0.3156123161315918\n",
      "Elapsed time: 0.20273995399475098\n",
      "Elapsed time: 0.2995741367340088\n",
      "Elapsed time: 0.23091602325439453\n",
      "Elapsed time: 0.3109092712402344\n",
      "Elapsed time: 0.21927189826965332\n",
      "Elapsed time: 0.313610315322876\n",
      "Elapsed time: 0.23351097106933594\n",
      "Elapsed time: 0.29486894607543945\n",
      "Elapsed time: 0.21988797187805176\n",
      "Elapsed time: 0.2971174716949463\n",
      "Elapsed time: 0.2223198413848877\n",
      "Elapsed time: 0.31522202491760254\n",
      "Elapsed time: 0.21528387069702148\n",
      "Elapsed time: 0.28452324867248535\n",
      "Elapsed time: 0.2684516906738281\n",
      "Elapsed time: 0.26430344581604004\n",
      "Elapsed time: 0.2245621681213379\n",
      "Elapsed time: 0.29965829849243164\n",
      "Elapsed time: 0.21612310409545898\n",
      "Elapsed time: 0.2939493656158447\n",
      "Elapsed time: 0.26651978492736816\n",
      "Elapsed time: 0.24681520462036133\n",
      "Elapsed time: 0.26471757888793945\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ex 1.4: Implement the efficient search for lambda \n",
    "# as disussed during the lecture. \n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_regression(n_samples=1500, n_features=50, random_state=0, noise=4.0, bias=0.0)\n",
    "\n",
    "gamma = 1.0 / 50.0\n",
    "lams = numpy.arange(0, 10, 0.1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.333333, random_state=1)\n",
    "\n",
    "model = LeastSquaresRegression(kernel=\"fast_rbf\", gamma=gamma, r=None)\n",
    "\n",
    "sols_shortcut = []\n",
    "elapsed_shortcut = []\n",
    "for lam in lams:\n",
    "    start = time.time()\n",
    "    model.fit_shortcut(X_train, y_train, lam=lam)\n",
    "    sols_shortcut.append(model._c)\n",
    "    end = time.time()\n",
    "    elapsed_shortcut.append(end-start)\n",
    "    print(\"Elapsed time: {}\".format(end-start))\n",
    "\n",
    "elapsed_normal = []\n",
    "sols_normal = []\n",
    "for lam in lams:    \n",
    "    model = LeastSquaresRegression(kernel=\"fast_rbf\", lam=lam, gamma=gamma, r=None)\n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    sols_normal.append(model._c)\n",
    "    end = time.time()\n",
    "    elapsed_normal.append(end-start)\n",
    "    print(\"Elapsed time: {}\".format(end-start))\n",
    "\n",
    "\n",
    "# sanity check: Are the computed solutions the same?\n",
    "for i in range(len(sols_normal)):\n",
    "    assert numpy.allclose(sols_normal[i], sols_shortcut[i])\n",
    "\n",
    "# runtime plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(len(lams)), elapsed_normal, label=\"fit\")\n",
    "ax.plot(range(len(lams)), elapsed_shortcut, label=\"fit shortcut\")\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
